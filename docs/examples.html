<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Examples &mdash; ABCPY - Scoring Rules 0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Added functions" href="features.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            ABCPY - Scoring Rules
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="Defining%20A%20Model.html">Defining A Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="features.html">Added functions</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Examples</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ABCPY - Scoring Rules</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Examples</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/examples.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="examples">
<h1>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>Example inference for user-defined Gaussian / G-and-K models / Array simulations</p>
<hr class="docutils" />
<p>Gaussian model</p>
<p>Say we have a set of observations which we know are generated from a gaussian distribution. We can use the following setup
to infer the model parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Number</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">abcpy.probabilisticmodels</span> <span class="kn">import</span> <span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">,</span> <span class="n">InputConnector</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd.functional</span> <span class="kn">import</span> <span class="n">jacobian</span>

<span class="k">class</span> <span class="nc">Gaussian</span><span class="p">(</span><span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">):</span>
        <span class="c1"># We expect input of type parameters = [mu, sigma]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Input of Normal model is of type list&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Input list must be of length 2, containing [mu, sigma].&#39;</span><span class="p">)</span>

        <span class="n">input_connector</span> <span class="o">=</span> <span class="n">InputConnector</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">input_connector</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_check_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">):</span>
        <span class="c1"># Check whether input has correct type or format</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_values</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Number of parameters of Normal model must be 2.&#39;</span><span class="p">)</span>
        <span class="c1"># Check whether input is from correct domain</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">sigma</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()):</span>
        <span class="c1"># Extract the input parameters</span>
        <span class="c1"># input_values = self.transform_variables(input_values) # do this outside in inference.</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normal_model_pytorch</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">input_value</span><span class="p">)</span> <span class="k">for</span> <span class="n">input_value</span> <span class="ow">in</span> <span class="n">input_values</span><span class="p">],</span> <span class="n">k</span><span class="p">)</span><span class="c1">#[np.array([x]) for x in vector_of_k_samples]</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">normal_model_pytorch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">return_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">]</span>
            <span class="n">yval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span> <span class="o">+</span> <span class="n">mu</span>
            <span class="n">value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yval</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">values</span>


    <span class="k">def</span> <span class="nf">grad_forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()):</span>
        <span class="c1"># Takes input in the form:  [a,....,z]</span>
        <span class="c1"># Outputs: array: [x1, x2, ...... ,xn, [dx1/dtheta1, dx1/dtheta2], ...... [dxn/dtheta1, dxn/dtheta2],]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_normal_model_pytorch</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">input_value</span><span class="p">)</span> <span class="k">for</span> <span class="n">input_value</span> <span class="ow">in</span> <span class="n">input_values</span><span class="p">],</span> <span class="n">k</span><span class="p">)</span><span class="c1">#[np.array([x]) for x in vector_of_k_samples]</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">grad_normal_model_pytorch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">return_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">gradvalues</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">]</span>
            <span class="n">yval</span> <span class="o">=</span> <span class="n">z</span><span class="o">*</span><span class="n">sigma</span> <span class="o">+</span> <span class="n">mu</span>
            <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yval</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">yval</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">gradvalue</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
                <span class="n">gradvalue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">gradvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gradvalue</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">values</span> <span class="o">+</span> <span class="n">gradvalues</span>

    <span class="k">def</span> <span class="nf">_check_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Output of the normal distribution is always a number.&#39;</span><span class="p">)</span>

        <span class="c1"># At this point values is a number (int, float); full domain for Normal is allowed</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">get_output_dimension</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">jacobian_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>

    <span class="k">def</span> <span class="nf">transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>

    <span class="k">def</span> <span class="nf">inverse_transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span>
</pre></div>
</div>
<p>and then call run the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">abcpy.approx_lhd</span> <span class="kn">import</span> <span class="n">EnergyScore</span><span class="p">,</span> <span class="n">KernelScore</span>
<span class="kn">from</span> <span class="nn">abcpy.backends</span> <span class="kn">import</span> <span class="n">BackendDummy</span>
<span class="kn">from</span> <span class="nn">abcpy.continuousmodels</span> <span class="kn">import</span> <span class="n">Normal</span><span class="p">,</span> <span class="n">LogNormal</span>
<span class="kn">from</span> <span class="nn">abcpy.inferences</span> <span class="kn">import</span> <span class="n">adSGLD</span><span class="p">,</span> <span class="n">SGLD</span>
<span class="kn">from</span> <span class="nn">abcpy.statistics</span> <span class="kn">import</span> <span class="n">Identity</span>
<span class="kn">from</span> <span class="nn">Gaussian_model</span> <span class="kn">import</span> <span class="n">Gaussian</span>

<span class="c1"># setup backend</span>
<span class="n">dummy</span> <span class="o">=</span> <span class="n">BackendDummy</span><span class="p">()</span>

<span class="n">mu</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mu&#39;</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sigma&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Gaussian</span><span class="p">([</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">])</span>

<span class="n">stat_calc</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cross</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">dist_calc</span> <span class="o">=</span> <span class="n">EnergyScore</span><span class="p">(</span><span class="n">stat_calc</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y_obs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward_simulate</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">adSGLD</span><span class="p">([</span><span class="n">model</span><span class="p">],</span> <span class="p">[</span><span class="n">dist_calc</span><span class="p">],</span> <span class="n">dummy</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">journal</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="n">y_obs</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">w_val</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">diffusion_factor</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">path_to_save_journal</span><span class="o">=</span><span class="s2">&quot;tmp.jnl&quot;</span><span class="p">)</span>

<span class="n">journal</span><span class="o">.</span><span class="n">plot_posterior_distr</span><span class="p">(</span><span class="n">path_to_save</span><span class="o">=</span><span class="s2">&quot;posterior.png&quot;</span><span class="p">)</span>
<span class="n">journal</span><span class="o">.</span><span class="n">traceplot</span><span class="p">()</span>
</pre></div>
</div>
<p>This generates a posterior plot of the sampled parameters for the mean and standard deviation. Here we generate our y_obs directly from the same
model, however the user could replace this with any properly formatted dataset and the sampler should converge whenever the prior values of mu and sigma provide reasonable
coverage of the true parameters and the model is properly specified (ie the observations are actually normally distributed) (note here that the values for w_val, step_size and burn in may need to be
adjusted to ensure convergence depending on how close your priors are to the true distribution)</p>
<p>We give below another example using the kernelscore with a user defined rbf kernel using the SGLD algorithm</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">abcpy.approx_lhd</span> <span class="kn">import</span> <span class="n">SynLikelihood</span><span class="p">,</span> <span class="n">EnergyScore</span><span class="p">,</span> <span class="n">KernelScore</span>
<span class="kn">from</span> <span class="nn">abcpy.backends</span> <span class="kn">import</span> <span class="n">BackendDummy</span>
<span class="kn">from</span> <span class="nn">abcpy.continuousmodels</span> <span class="kn">import</span> <span class="n">Normal</span><span class="p">,</span> <span class="n">LogNormal</span>
<span class="kn">from</span> <span class="nn">abcpy.inferences</span> <span class="kn">import</span> <span class="n">adSGLD</span><span class="p">,</span> <span class="n">SGLD</span>
<span class="kn">from</span> <span class="nn">abcpy.statistics</span> <span class="kn">import</span> <span class="n">Identity</span>
<span class="kn">from</span> <span class="nn">Gaussian_model</span> <span class="kn">import</span> <span class="n">Gaussian</span>


<span class="k">def</span> <span class="nf">BetaNormNeg</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;x2 should be a 1D tensor&quot;</span>
    <span class="k">assert</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">==</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;The last dimensions of x1 and x2 should match&quot;</span>

    <span class="c1"># Subtract x2 from all entries in x1 and compute the beta norm</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span>
    <span class="n">norm_beta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">beta</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">norm_beta</span>

<span class="c1"># setup backend</span>
<span class="n">dummy</span> <span class="o">=</span> <span class="n">BackendDummy</span><span class="p">()</span>

<span class="c1"># define a uniform prior distribution</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mu&#39;</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sigma&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Gaussian</span><span class="p">([</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">])</span>

<span class="n">stat_calc</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cross</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dist_calc</span> <span class="o">=</span> <span class="n">KernelScore</span><span class="p">(</span><span class="n">stat_calc</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">BetaNormNeg</span><span class="p">)</span>

<span class="n">y_obs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward_simulate</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>  <span class="c1"># Correct</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">SGLD</span><span class="p">([</span><span class="n">model</span><span class="p">],</span> <span class="p">[</span><span class="n">dist_calc</span><span class="p">],</span> <span class="n">dummy</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">journal</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="n">y_obs</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">,</span> <span class="n">w_val</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">diffusion_factor</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">path_to_save_journal</span><span class="o">=</span><span class="s2">&quot;tmp.jnl&quot;</span><span class="p">)</span>

<span class="n">journal</span><span class="o">.</span><span class="n">plot_posterior_distr</span><span class="p">(</span><span class="n">path_to_save</span><span class="o">=</span><span class="s2">&quot;posterior.png&quot;</span><span class="p">)</span>
<span class="n">journal</span><span class="o">.</span><span class="n">traceplot</span><span class="p">()</span>
</pre></div>
</div>
<p>G-and-K Model</p>
<p>We define another model below for a simple g and k model [M. A. Haynes et al,  Robustness of ranking and selection rules
using generalised g-and-k distributions. Journal of Statistical Planning and Inference, 1997.] with four input parameters
The code is provided here:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Number</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>

<span class="kn">from</span> <span class="nn">abcpy.probabilisticmodels</span> <span class="kn">import</span> <span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">,</span> <span class="n">InputConnector</span>

<span class="k">class</span> <span class="nc">G_and_K</span><span class="p">(</span><span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;G_and_K&#39;</span><span class="p">):</span>
        <span class="c1"># We expect input of type parameters = [mu, sigma]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Input of Normal model is of type list&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Input list must be of length 4, containing [A, B, g, k].&#39;</span><span class="p">)</span>

        <span class="n">input_connector</span> <span class="o">=</span> <span class="n">InputConnector</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">input_connector</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_check_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">):</span>
        <span class="c1"># Check whether input has correct type or format</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_values</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Number of parameters of Normal model must be 4.&#39;</span><span class="p">)</span>

        <span class="c1"># Check whether input is from correct domain</span>
        <span class="k">if</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_check_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">get_output_dimension</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">g_and_k_quantile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="n">c1</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">))</span>
        <span class="n">c2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">c3</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)))</span>
        <span class="n">c4</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">24</span>

        <span class="k">return</span> <span class="n">A</span> <span class="o">+</span> <span class="n">B</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">c1</span><span class="o">*</span><span class="n">y</span> <span class="o">+</span> <span class="n">c2</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">c3</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="n">c4</span><span class="o">*</span><span class="n">y</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="n">k</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">g</span><span class="o">*</span><span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">to_list</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># Sample from standard normal</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

        <span class="c1"># Return quantile values</span>
        <span class="k">if</span> <span class="n">to_list</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_and_k_quantile</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">params</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_and_k_quantile</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">params</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">grad_forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">2</span><span class="p">])),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>
        <span class="n">A</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">B</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">g</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">k</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_simulate</span><span class="p">([</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">n</span><span class="p">,</span> <span class="n">to_list</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="n">s</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">A</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">B</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">g</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">k</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
            <span class="n">A</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">B</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">g</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">k</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">samples</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">grads</span>

    <span class="k">def</span> <span class="nf">transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>

    <span class="k">def</span> <span class="nf">inverse_transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span>

    <span class="k">def</span> <span class="nf">jacobian_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>
</pre></div>
</div>
<p>and then running the following to infer the the A and B parameter</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">BackendDummy</span><span class="p">()</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">)</span>
<span class="c1">#g = Normal([0, 1], name=&#39;g&#39;)</span>
<span class="c1">#k = Normal([0, 1], name=&#39;k&#39;)</span>

<span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">G_and_K</span><span class="p">([</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># define sufficient statistics for the model</span>
<span class="n">stat_calc</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cross</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">dist_calc</span> <span class="o">=</span> <span class="n">EnergyScore</span><span class="p">(</span><span class="n">stat_calc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># create fake observed data</span>
<span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward_simulate</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>  <span class="c1"># Correct</span>
<span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">adSGLD</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">],</span> <span class="p">[</span><span class="n">dist_calc</span><span class="p">],</span> <span class="n">dummy</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="c1">#basic_adSGLD([self.model], [dist_calc], dummy, seed=1)</span>
<span class="n">journal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">y_obs</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mf">0.0003</span><span class="p">,</span> <span class="n">w_val</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">diffusion_factor</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">path_to_save_journal</span><span class="o">=</span><span class="s2">&quot;tmp.jnl&quot;</span><span class="p">)</span>
<span class="n">journal</span><span class="o">.</span><span class="n">plot_posterior_distr</span><span class="p">(</span><span class="n">path_to_save</span><span class="o">=</span><span class="s2">&quot;posterior.png&quot;</span><span class="p">)</span>
<span class="n">journal</span><span class="o">.</span><span class="n">traceplot</span><span class="p">()</span>
</pre></div>
</div>
<p>Producing the following output for our plot, correctly estimating the posterior values 5 and 1 (increasing the
number of posterior samples will increase the accuracy of this posterior distribution even further)</p>
<a class="reference internal image-reference" href="_images/gandkmodelposterior.png"><img alt="Alternative text" src="_images/gandkmodelposterior.png" style="width: 400px;" /></a>
<p>Array simulations</p>
<p>The Scoring rule setup allows for user defined models which produce multiple elements per simulation, we give an example
below of a function which produces pairs of values from a gaussian distribution with the same parameters. This setup
can be used to analyse models which produce time series (for example in a
lorenz 95 model) or which have other correlated variables.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Number</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">abcpy.probabilisticmodels</span> <span class="kn">import</span> <span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">,</span> <span class="n">InputConnector</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd.functional</span> <span class="kn">import</span> <span class="n">jacobian</span>

<span class="k">class</span> <span class="nc">DualGaussian</span><span class="p">(</span><span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">):</span>
        <span class="c1"># We expect input of type parameters = [mu, sigma]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Input of Normal model is of type list&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Input list must be of length 2, containing [mu, sigma].&#39;</span><span class="p">)</span>

        <span class="n">input_connector</span> <span class="o">=</span> <span class="n">InputConnector</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">input_connector</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_check_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">):</span>
        <span class="c1"># Check whether input has correct type or format</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_values</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Number of parameters of Normal model must be 2.&#39;</span><span class="p">)</span>
        <span class="c1"># Check whether input is from correct domain</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">sigma</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()):</span>
        <span class="c1"># Extract the input parameters</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normal_model_pytorch</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">input_value</span><span class="p">)</span> <span class="k">for</span> <span class="n">input_value</span> <span class="ow">in</span> <span class="n">input_values</span><span class="p">],</span> <span class="n">k</span><span class="p">)</span><span class="c1">#[np.array([x]) for x in vector_of_k_samples]</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">normal_model_pytorch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">return_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu</span><span class="p">,</span><span class="n">sigma</span><span class="p">]</span>
            <span class="n">yval1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span> <span class="o">+</span> <span class="n">mu</span>
            <span class="n">yval2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span> <span class="o">+</span> <span class="n">mu</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">yval1</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span><span class="n">yval2</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>
            <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">values</span>


    <span class="k">def</span> <span class="nf">grad_forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()):</span>
        <span class="c1"># Takes input in the form:  [a,....,z]</span>
        <span class="c1"># Outputs: array: [x1, x2, ...... ,xn, [dx1/dtheta1, dx1/dtheta2], ...... [dxn/dtheta1, dxn/dtheta2],]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_normal_model_pytorch</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">input_value</span><span class="p">)</span> <span class="k">for</span> <span class="n">input_value</span> <span class="ow">in</span> <span class="n">input_values</span><span class="p">],</span> <span class="n">k</span><span class="p">)</span><span class="c1">#[np.array([x]) for x in vector_of_k_samples]</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">grad_normal_model_pytorch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">return_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">gradvalues</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="n">mu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">sigma1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">z1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">variables1</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu1</span><span class="p">,</span><span class="n">sigma1</span><span class="p">]</span>
            <span class="n">yval1</span> <span class="o">=</span> <span class="n">z1</span><span class="o">*</span><span class="n">sigma1</span> <span class="o">+</span> <span class="n">mu1</span>
            <span class="n">yval1</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">mu2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">sigma2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_values</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">z2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">variables2</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu2</span><span class="p">,</span><span class="n">sigma2</span><span class="p">]</span>
            <span class="n">yval2</span> <span class="o">=</span> <span class="n">z2</span><span class="o">*</span><span class="n">sigma2</span> <span class="o">+</span> <span class="n">mu2</span>
            <span class="n">yval2</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">yval1</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span><span class="n">yval2</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

            <span class="n">gradvalue1</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables1</span><span class="p">:</span>
                <span class="n">gradvalue1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="n">gradvalue2</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables2</span><span class="p">:</span>
                <span class="n">gradvalue2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="n">gradvalues</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">gradvalue1</span><span class="p">,</span> <span class="n">gradvalue2</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">values</span> <span class="o">+</span> <span class="n">gradvalues</span>

    <span class="k">def</span> <span class="nf">_check_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">Number</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Output of the normal distribution is always a number.&#39;</span><span class="p">)</span>

        <span class="c1"># At this point values is a number (int, float); full domain for Normal is allowed</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">get_output_dimension</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">jacobian_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>

    <span class="k">def</span> <span class="nf">transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>

    <span class="k">def</span> <span class="nf">inverse_transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span>
</pre></div>
</div>
<p>and this can be called as before with</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">abcpy.approx_lhd</span> <span class="kn">import</span> <span class="n">SynLikelihood</span><span class="p">,</span> <span class="n">EnergyScore</span><span class="p">,</span> <span class="n">KernelScore</span>
<span class="kn">from</span> <span class="nn">abcpy.backends</span> <span class="kn">import</span> <span class="n">BackendDummy</span>
<span class="kn">from</span> <span class="nn">abcpy.continuousmodels</span> <span class="kn">import</span> <span class="n">Normal</span><span class="p">,</span> <span class="n">LogNormal</span>
<span class="kn">from</span> <span class="nn">abcpy.inferences</span> <span class="kn">import</span> <span class="n">adSGLD</span><span class="p">,</span> <span class="n">SGLD</span>
<span class="kn">from</span> <span class="nn">abcpy.statistics</span> <span class="kn">import</span> <span class="n">Identity</span>
<span class="kn">from</span> <span class="nn">DualGaussianFile</span> <span class="kn">import</span> <span class="n">DualGaussian</span>

<span class="c1"># setup backend</span>
<span class="n">dummy</span> <span class="o">=</span> <span class="n">BackendDummy</span><span class="p">()</span>

<span class="c1"># define a uniform prior distribution</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mu&#39;</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sigma&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Gaussian</span><span class="p">([</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">])</span>

<span class="n">stat_calc</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cross</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">dist_calc</span> <span class="o">=</span> <span class="n">EnergyScore</span><span class="p">(</span><span class="n">stat_calc</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">y_obs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward_simulate</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>  <span class="c1"># Correct</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">SGLD</span><span class="p">([</span><span class="n">model</span><span class="p">],</span> <span class="p">[</span><span class="n">dist_calc</span><span class="p">],</span> <span class="n">dummy</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">journal</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="n">y_obs</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">w_val</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">diffusion_factor</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">path_to_save_journal</span><span class="o">=</span><span class="s2">&quot;tmp.jnl&quot;</span><span class="p">)</span>

<span class="n">journal</span><span class="o">.</span><span class="n">plot_posterior_distr</span><span class="p">(</span><span class="n">path_to_save</span><span class="o">=</span><span class="s2">&quot;posterior.png&quot;</span><span class="p">)</span>
<span class="n">journal</span><span class="o">.</span><span class="n">traceplot</span><span class="p">()</span>
</pre></div>
</div>
<p>producing the following output plot:</p>
<a class="reference internal image-reference" href="_images/DualGaussian.png"><img alt="Alternative text" src="_images/DualGaussian.png" style="width: 400px;" /></a>
<p>Time Series simulation</p>
<p>We develop the following toy time series simulator which simulates a time series starting
at zero and adding a parameter rate and a standard normal(0,1) error term at
each iteration over t steps.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Number</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">abcpy.probabilisticmodels</span> <span class="kn">import</span> <span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">,</span> <span class="n">InputConnector</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">IncreasingTimeSeries</span><span class="p">(</span><span class="n">ProbabilisticModel</span><span class="p">,</span> <span class="n">Continuous</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;IncreasingTimeSeries&#39;</span><span class="p">):</span>
        <span class="c1"># We expect input of type parameters = [rate]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Input of IncreasingTimeSeries model is of type list&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Input list must be of length 1, containing [rate].&#39;</span><span class="p">)</span>

        <span class="n">input_connector</span> <span class="o">=</span> <span class="n">InputConnector</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">input_connector</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">timesteps</span> <span class="o">=</span> <span class="n">timesteps</span>  <span class="c1"># Setting the length of the time series</span>

    <span class="k">def</span> <span class="nf">_check_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_values</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Number of parameters of IncreasingTimeSeries model must be 1.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()):</span>
        <span class="n">rate</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">simulate_time_series</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span> <span class="nf">grad_forward_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_values</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()):</span>
        <span class="n">rate</span> <span class="o">=</span> <span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_simulate_time_series</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span> <span class="nf">simulate_time_series</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">rate</span><span class="p">):</span>

        <span class="n">fullvalues</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">current_value</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">timesteps</span><span class="p">):</span>
                <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">current_value</span> <span class="o">+=</span> <span class="n">rate</span> <span class="o">+</span> <span class="n">noise</span>
                <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_value</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">fullvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fullvalues</span>

    <span class="k">def</span> <span class="nf">grad_simulate_time_series</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">rate</span><span class="p">):</span>

        <span class="n">fullvalues</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">fullgrad</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="n">rate_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">current_value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">gradvalues</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">timesteps</span><span class="p">):</span>
                <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">new_value</span> <span class="o">=</span> <span class="n">current_value</span> <span class="o">+</span> <span class="n">rate_tensor</span> <span class="o">+</span> <span class="n">noise</span>
                <span class="n">new_value</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_value</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">gradvalues</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">rate_tensor</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

                <span class="c1"># Update current_value without modifying it in-place</span>
                <span class="n">current_value</span> <span class="o">=</span> <span class="n">new_value</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

                <span class="c1"># Zero out the gradients to ensure the accumulation does not happen</span>
                <span class="n">rate_tensor</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">fullvalues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
            <span class="n">fullgrad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gradvalues</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fullvalues</span> <span class="o">+</span> <span class="n">fullgrad</span>


    <span class="k">def</span> <span class="nf">_check_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="c1"># Check that the output is a list (or iterable)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">get_output_dimension</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">timesteps</span>

    <span class="k">def</span> <span class="nf">jacobian_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>

    <span class="k">def</span> <span class="nf">transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_transforms</span>

    <span class="k">def</span> <span class="nf">inverse_transform_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ordered_inverse_transforms</span>
</pre></div>
</div>
<p>We generate a set of 30 observations with rate parameter 6.0 each of length t=4 and run an sgld sampler on this time series with
the following parameters n samples = 300, n samples per param = 100, burn in
= 300, step size=0.0001, w val = 50. We run this sampler with a normal(9,3)
prior parameter on rate and get the following output</p>
<a class="reference internal image-reference" href="_images/TimeSeries6Simulation.png"><img alt="Alternative text" src="_images/TimeSeries6Simulation.png" style="width: 400px;" /></a>
<p>Showing that our approach is indeed able to correctly infer the parameters for a generative time-series model.
(note the variance in observations, increasing n_obs to 100 gives even closer
estimations to the true parameter 6.0)</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="features.html" class="btn btn-neutral float-left" title="Added functions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Timothy Moffitt.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>